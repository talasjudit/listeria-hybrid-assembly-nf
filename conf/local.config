/*
========================================================================================
    Local Executor Configuration
========================================================================================
    Configuration for running the pipeline on a local workstation or server

    This profile is suitable for:
    - Testing and development
    - Small datasets on powerful workstations
    - Single-node servers

    Important Notes:
    - All processes run sequentially or with limited parallelism (controlled by maxForks)
    - Total resource usage is controlled by params.max_cpus and params.max_memory
    - Not recommended for large production runs (use SLURM profile instead)

    Usage:
      nextflow run main.nf -profile local,singularity --input samplesheet.csv
========================================================================================
*/

process {
    executor = 'local'

    /*
     * Limit Concurrent Processes
     * Controls how many processes can run simultaneously
     *
     * maxForks = 1 : Fully sequential execution (one process at a time)
     * maxForks = 2 : Up to 2 processes can run concurrently
     * maxForks = 4 : Up to 4 processes can run concurrently (default)
     *
     * Note: Even with maxForks > 1, Nextflow respects max_cpus and max_memory
     * from params, so total resource usage won't exceed your limits
     */
    maxForks = 4

    /*
     * Error Strategy
     * For local execution, it's often better to fail fast
     * This can be overridden on a per-process basis in base.config
     */
    errorStrategy = 'finish'

    /*
     * Working Directory
     * By default, Nextflow uses ./work in the project directory
     * Uncomment to specify a different location (e.g., faster storage)
     */
    // workDir = '/path/to/fast/scratch/space/work'
}

/*
========================================================================================
    EXECUTOR SETTINGS
========================================================================================
*/

executor {
    /*
     * Local Executor Resource Limits
     * These should match your system capabilities
     * They're initialized from params but can be overridden here
     *
     * To check your system resources:
     * - CPUs: nproc (Linux) or sysctl -n hw.ncpu (macOS)
     * - Memory: free -h (Linux) or sysctl hw.memsize (macOS)
     */
    cpus   = params.max_cpus
    memory = params.max_memory

    /*
     * For local execution, these are less relevant but can be set
     */
    // queueSize = 1  // Only relevant if using maxForks > 1
}

/*
========================================================================================
    SINGULARITY SETTINGS
========================================================================================
*/

singularity {
    enabled     = true
    autoMounts  = true
    cacheDir    = params.singularity_cachedir

    /*
     * For local execution, you may want to bind mount additional directories
     * Example: If your data is on an external drive
     */
    // runOptions = '--bind /mnt/data:/data'

    /*
     * On macOS or systems with limited /tmp space, you may want to set TMPDIR
     */
    // envWhitelist = 'TMPDIR'
}

/*
========================================================================================
    NOTES FOR LOCAL EXECUTION
========================================================================================

    1. Resource Planning:
       - Check available resources before running
       - Set max_cpus and max_memory conservatively
       - Leave some resources for the operating system

    2. Recommended Settings by System Size:

       Small workstation (8 cores, 16GB RAM):
       --max_cpus 6 --max_memory 12.GB

       Medium workstation (16 cores, 32GB RAM):
       --max_cpus 12 --max_memory 24.GB

       Large workstation (32 cores, 64GB RAM):
       --max_cpus 24 --max_memory 48.GB

    3. Performance Tips:
       - Use SSD storage for working directory if possible
       - Close other applications to free up resources
       - Consider running overnight for large datasets
       - Use -resume to restart failed runs without repeating completed steps

    4. When to Use Local vs SLURM:
       Use Local for:
       - Testing with small datasets
       - Development and debugging
       - Systems without a job scheduler

       Use SLURM for:
       - Production runs with multiple samples
       - Large datasets requiring >64GB RAM
       - When you need to run multiple pipelines concurrently

    5. Monitoring Local Execution:
       - CPU usage: top or htop
       - Memory usage: free -h (Linux) or Activity Monitor (macOS)
       - Disk I/O: iotop (Linux) or Activity Monitor (macOS)
       - Nextflow progress: Check the console output

    6. Common Issues:
       - "Out of memory" : Reduce max_memory or maxForks
       - "Too slow" : Increase maxForks if you have CPU headroom
       - "Disk full" : Check work directory size, use -resume to restart

========================================================================================
*/
